{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2021, InterDigital R&D France. All rights reserved.\n",
    "\n",
    "# This source code is made available under the license found in the\n",
    "# LICENSE.txt in the root directory of this source tree.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets \n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import yaml\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "import sys\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    sys.path.append('..')\n",
    "    os.chdir('..')\n",
    "    \n",
    "from datasets import *\n",
    "from trainer import *\n",
    "from utils.functions import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "device = torch.device('cuda')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='001', help='Path to the config file.')\n",
    "parser.add_argument('--attr', type=str, default='Eyeglasses', help='attribute for manipulation.')\n",
    "parser.add_argument('--latent_path', type=str, default='./data/celebahq_dlatents_psp.npy', help='dataset path')\n",
    "parser.add_argument('--label_file', type=str, default='./data/celebahq_anno.npy', help='label file path')\n",
    "parser.add_argument('--stylegan_model_path', type=str, default='./pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt', help='stylegan model path')\n",
    "parser.add_argument('--classifier_model_path', type=str, default='./models/latent_classifier_epoch_20.pth', help='pretrained attribute classifier')\n",
    "parser.add_argument('--log_path', type=str, default='./logs/', help='log file path')\n",
    "opts = parser.parse_args([])\n",
    "\n",
    "# Celeba attribute list\n",
    "attr_dict = {'5_o_Clock_Shadow': 0, 'Arched_Eyebrows': 1, 'Attractive': 2, 'Bags_Under_Eyes': 3, \\\n",
    "            'Bald': 4, 'Bangs': 5, 'Big_Lips': 6, 'Big_Nose': 7, 'Black_Hair': 8, 'Blond_Hair': 9, \\\n",
    "            'Blurry': 10, 'Brown_Hair': 11, 'Bushy_Eyebrows': 12, 'Chubby': 13, 'Double_Chin': 14, \\\n",
    "            'Eyeglasses': 15, 'Goatee': 16, 'Gray_Hair': 17, 'Heavy_Makeup': 18, 'High_Cheekbones': 19, \\\n",
    "            'Male': 20, 'Mouth_Slightly_Open': 21, 'Mustache': 22, 'Narrow_Eyes': 23, 'No_Beard': 24, \\\n",
    "            'Oval_Face': 25, 'Pale_Skin': 26, 'Pointy_Nose': 27, 'Receding_Hairline': 28, 'Rosy_Cheeks': 29, \\\n",
    "            'Sideburns': 30, 'Smiling': 31, 'Straight_Hair': 32, 'Wavy_Hair': 33, 'Wearing_Earrings': 34, \\\n",
    "            'Wearing_Hat': 35, 'Wearing_Lipstick': 36, 'Wearing_Necklace': 37, 'Wearing_Necktie': 38, 'Young': 39}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer model.\n",
    "log_dir = os.path.join(opts.log_path, opts.config) + '/'\n",
    "config = yaml.load(open('./configs/' + opts.config + '.yaml', 'r'))\n",
    "\n",
    "trainer = Trainer(config, None, None, opts.label_file)\n",
    "trainer.initialize(opts.stylegan_model_path, opts.classifier_model_path)   \n",
    "trainer.to(device)\n",
    "print('Load model.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulization of attribute manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set desired attributes for manipulation in attr_list\n",
    "attr_list = ['Male','Eyeglasses','Young','Smiling']\n",
    "testdata_dir = './data/test/'\n",
    "\n",
    "# Load latent transformer models\n",
    "T_net_dict = {}\n",
    "for attr in attr_list:\n",
    "    trainer.attr_num = attr_dict[attr]\n",
    "    trainer.load_model(log_dir)\n",
    "    T_net_dict[attr] = copy.deepcopy(trainer.T_net)\n",
    "    \n",
    "# Visualization function\n",
    "def visu_manipulation(seed, **attr_scale):\n",
    "    with torch.no_grad():\n",
    "        w_0 = np.load(testdata_dir + 'latent_code_%05d.npy'%int(seed))\n",
    "        w_0 = torch.tensor(w_0).to(device)\n",
    "        w_1 = w_0\n",
    "        for key in attr_scale.keys():\n",
    "            if attr_scale[key] != 0:\n",
    "                w_1 = T_net_dict[key](w_1.view(w_0.size(0),-1), torch.tensor(attr_scale[key]).unsqueeze(0).to(device))\n",
    "        w_1 = w_1.view(w_0.size())\n",
    "        w_1 = torch.cat((w_1[:,:11,:], w_0[:,11:,:]), 1)\n",
    "        x_1, _ = trainer.StyleGAN([w_1], input_is_latent=True, randomize_noise=False)\n",
    "        img = np.clip(clip_img(x_1)[0].cpu().numpy()*255.,0,255).astype(np.uint8)\n",
    "        img = Image.fromarray(img.transpose(1,2,0))\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# User interface\n",
    "%matplotlib inline\n",
    "attr_scale = {key: (-1.5,1.5,0.3) for key in attr_list}\n",
    "interact(visu_manipulation, seed=[0,1,2,3,4,5,6,7,8], **attr_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
